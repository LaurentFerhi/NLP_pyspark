{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_pyspark.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5a-MB_8RycG"
      },
      "source": [
        "# Spam detector using pyspark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpAJX9aXH3xb",
        "outputId": "1c0ad6a3-d0e2-4e6c-a087-8f7892a71c17"
      },
      "source": [
        "pip install pyspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/26/198fc8c0b98580f617cb03cb298c6056587b8f0447e20fa40c5b634ced77/pyspark-3.0.1.tar.gz (204.2MB)\n",
            "\u001b[K     |████████████████████████████████| 204.2MB 66kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 49.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.1-py2.py3-none-any.whl size=204612242 sha256=4645b376bc700d032ca43627fd7a29726c26b6dd277adaa8418b0ca26803850f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/bd/07/031766ca628adec8435bb40f0bd83bb676ce65ff4007f8e73f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVrnmlVHIIVa"
      },
      "source": [
        "from pyspark.sql import SparkSession\r\n",
        "spark = SparkSession.builder.appName('NLP').getOrCreate()"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "955gjkT_JCD2"
      },
      "source": [
        "from pyspark.sql.functions import length\r\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer, VectorAssembler\r\n",
        "from pyspark.ml.classification import NaiveBayes\r\n",
        "from pyspark.ml import Pipeline\r\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\r\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\r\n",
        "\r\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t_JEQocR5aM"
      },
      "source": [
        "## Data wrangling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0seBEN6IXXm",
        "outputId": "e8a987e9-f3a4-4a07-9a81-9b58947dd998"
      },
      "source": [
        "data = spark.read.csv('SMSSpamCollection',inferSchema=True,sep='\\t')\r\n",
        "data.show(5)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+--------------------+\n",
            "| _c0|                 _c1|\n",
            "+----+--------------------+\n",
            "| ham|Go until jurong p...|\n",
            "| ham|Ok lar... Joking ...|\n",
            "|spam|Free entry in 2 a...|\n",
            "| ham|U dun say so earl...|\n",
            "| ham|Nah I don't think...|\n",
            "+----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myyzoP2AIxeA",
        "outputId": "b559c486-1449-478e-da23-bb6768561d85"
      },
      "source": [
        "data = data.withColumnRenamed('_c0','target').withColumnRenamed('_c1','text')\r\n",
        "data.show(5)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+--------------------+\n",
            "|target|                text|\n",
            "+------+--------------------+\n",
            "|   ham|Go until jurong p...|\n",
            "|   ham|Ok lar... Joking ...|\n",
            "|  spam|Free entry in 2 a...|\n",
            "|   ham|U dun say so earl...|\n",
            "|   ham|Nah I don't think...|\n",
            "+------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMHdEBtRJKz3",
        "outputId": "6019fa2d-f0f2-40bb-eb87-08cdb4ecfe09"
      },
      "source": [
        "data = data.withColumn('length',length(data['text']))\r\n",
        "data.show(5)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+--------------------+------+\n",
            "|target|                text|length|\n",
            "+------+--------------------+------+\n",
            "|   ham|Go until jurong p...|   111|\n",
            "|   ham|Ok lar... Joking ...|    29|\n",
            "|  spam|Free entry in 2 a...|   155|\n",
            "|   ham|U dun say so earl...|    49|\n",
            "|   ham|Nah I don't think...|    61|\n",
            "+------+--------------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZ2hraowJZPw",
        "outputId": "14c9b690-54bb-46e5-e7bd-18f549f249cf"
      },
      "source": [
        "data.groupBy('target').mean().show()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-----------------+\n",
            "|target|      avg(length)|\n",
            "+------+-----------------+\n",
            "|   ham|71.45431945307645|\n",
            "|  spam|138.6706827309237|\n",
            "+------+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvMS2hCLNA4G"
      },
      "source": [
        "# NLP tools\r\n",
        "tokenizer = Tokenizer(inputCol='text', outputCol='token_text')\r\n",
        "stop_rm = StopWordsRemover(inputCol='token_text', outputCol='stop_token')\r\n",
        "count_vect = CountVectorizer(inputCol='stop_token', outputCol=('c_vec'))\r\n",
        "idf = IDF(inputCol='c_vec', outputCol='tf_idf')\r\n",
        "\r\n",
        "# Label encoder\r\n",
        "label_enc = StringIndexer(inputCol='target', outputCol='label')\r\n",
        "\r\n",
        "# Vector assembler\r\n",
        "featured_data = VectorAssembler(inputCols=['tf_idf','length'], outputCol='features')\r\n",
        "\r\n",
        "# Pre-process data\r\n",
        "pre_processor = Pipeline(stages=[label_enc, tokenizer, stop_rm, count_vect, idf, featured_data])"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcCvtwOjOlH3",
        "outputId": "80c7333d-f973-4a0f-de41-19b9ffe1567b"
      },
      "source": [
        "cleaner = pre_processor.fit(data)\r\n",
        "clean_data = cleaner.transform(data)\r\n",
        "clean_data.show(5)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|target|                text|length|label|          token_text|          stop_token|               c_vec|              tf_idf|            features|\n",
            "+------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|   ham|Go until jurong p...|   111|  0.0|[go, until, juron...|[go, jurong, poin...|(13423,[7,11,31,6...|(13423,[7,11,31,6...|(13424,[7,11,31,6...|\n",
            "|   ham|Ok lar... Joking ...|    29|  0.0|[ok, lar..., joki...|[ok, lar..., joki...|(13423,[0,24,297,...|(13423,[0,24,297,...|(13424,[0,24,297,...|\n",
            "|  spam|Free entry in 2 a...|   155|  1.0|[free, entry, in,...|[free, entry, 2, ...|(13423,[2,13,19,3...|(13423,[2,13,19,3...|(13424,[2,13,19,3...|\n",
            "|   ham|U dun say so earl...|    49|  0.0|[u, dun, say, so,...|[u, dun, say, ear...|(13423,[0,70,80,1...|(13423,[0,70,80,1...|(13424,[0,70,80,1...|\n",
            "|   ham|Nah I don't think...|    61|  0.0|[nah, i, don't, t...|[nah, think, goes...|(13423,[36,134,31...|(13423,[36,134,31...|(13424,[36,134,31...|\n",
            "+------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGS9U2GaQyX8",
        "outputId": "46d6a5a1-43f6-4514-e98f-3bf946c89c2c"
      },
      "source": [
        "clean_data.head(1)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(target='ham', text='Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', length=111, label=0.0, token_text=['go', 'until', 'jurong', 'point,', 'crazy..', 'available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet...', 'cine', 'there', 'got', 'amore', 'wat...'], stop_token=['go', 'jurong', 'point,', 'crazy..', 'available', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet...', 'cine', 'got', 'amore', 'wat...'], c_vec=SparseVector(13423, {7: 1.0, 11: 1.0, 31: 1.0, 61: 1.0, 72: 1.0, 344: 1.0, 625: 1.0, 731: 1.0, 1409: 1.0, 1598: 1.0, 4485: 1.0, 6440: 1.0, 8092: 1.0, 8838: 1.0, 11344: 1.0, 12979: 1.0}), tf_idf=SparseVector(13423, {7: 3.1126, 11: 3.2055, 31: 3.822, 61: 4.2072, 72: 4.322, 344: 5.4072, 625: 5.918, 731: 6.1411, 1409: 6.6801, 1598: 6.8343, 4485: 7.5274, 6440: 7.9329, 8092: 7.9329, 8838: 7.9329, 11344: 7.9329, 12979: 7.9329}), features=SparseVector(13424, {7: 3.1126, 11: 3.2055, 31: 3.822, 61: 4.2072, 72: 4.322, 344: 5.4072, 625: 5.918, 731: 6.1411, 1409: 6.6801, 1598: 6.8343, 4485: 7.5274, 6440: 7.9329, 8092: 7.9329, 8838: 7.9329, 11344: 7.9329, 12979: 7.9329, 13423: 111.0}))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61kvgNFVQ7S3"
      },
      "source": [
        "clean_data_training = clean_data.select('features','label')"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMzmgjrdRvTB"
      },
      "source": [
        "## Machine learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXjYbudMRTir"
      },
      "source": [
        "train, test = clean_data_training.randomSplit([0.7,0.3])"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jttCQYMLSeDh",
        "outputId": "301c4560-4f73-4e7d-ded2-f4bb6a61be97"
      },
      "source": [
        "# Evaluator precises the target column and the kind of metrics to use \r\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='label', metricName='f1')\r\n",
        "\r\n",
        "# Define transformtions stages to throw in the pipeline\r\n",
        "nb = NaiveBayes()\r\n",
        "\r\n",
        "# Definition of pipeline\r\n",
        "pipeline_nb = Pipeline(stages=[nb])\r\n",
        "\r\n",
        "# Definition of the grid parameters\r\n",
        "paramGrid = ParamGridBuilder().\\\r\n",
        "            addGrid(nb.modelType, [\"multinomial\"]).\\\r\n",
        "            build()\r\n",
        "\r\n",
        "# Definition of the cross validator\r\n",
        "cv = CrossValidator(\r\n",
        "  estimator=pipeline_nb,\r\n",
        "  estimatorParamMaps=paramGrid, \r\n",
        "  evaluator=evaluator, \r\n",
        "  numFolds=3)\r\n",
        "\r\n",
        "# Train the model\r\n",
        "spam_detector = cv.fit(train)\r\n",
        "\r\n",
        "# Predict classes on test part\r\n",
        "predictions = spam_detector.transform(test)\r\n",
        "predictions.show(5)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----+--------------------+--------------------+----------+\n",
            "|            features|label|       rawPrediction|         probability|prediction|\n",
            "+--------------------+-----+--------------------+--------------------+----------+\n",
            "|(13424,[0,1,2,4,3...|  1.0|[-1223.5862404983...|[4.33774984620535...|       1.0|\n",
            "|(13424,[0,1,2,5,5...|  1.0|[-933.08697008017...|[0.99999999999999...|       0.0|\n",
            "|(13424,[0,1,2,7,8...|  0.0|[-799.04508012095...|[1.0,1.9306915449...|       0.0|\n",
            "|(13424,[0,1,2,12,...|  1.0|[-1138.9496199184...|[1.97863320002813...|       1.0|\n",
            "|(13424,[0,1,2,15,...|  1.0|[-1158.3840510377...|[1.25255646716027...|       1.0|\n",
            "+--------------------+-----+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VokbfCMFSAwr",
        "outputId": "e2f0992c-4d43-4c91-bc6b-79614b7d34cd"
      },
      "source": [
        "predictions_pd = predictions.toPandas()\r\n",
        "print(classification_report(predictions_pd.prediction, predictions_pd.label))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.99      0.94      1352\n",
            "         1.0       0.97      0.59      0.73       383\n",
            "\n",
            "    accuracy                           0.90      1735\n",
            "   macro avg       0.93      0.79      0.84      1735\n",
            "weighted avg       0.91      0.90      0.90      1735\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}